<!DOCTYPE html>
<html lang="es">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.1.0">
  <meta name="generator" content="Hugo 0.50" />
  <meta name="author" content="Ricardo Holguin Esquer">

  
  
  
  
    
  
  <meta name="description" content="Dimensión VC La dimensión VC es definido por Vapnik y Chervonenkis, quienes dicen que cada clasificador tiene una dimension VC, el cual es la cardinalidad (tamaño) del conjunto más grande de datos que el clasificador pueda desentrañar.
Es importante entender la importancia práctica de la dimensión VC. En muchos casos, el número exacto de la dimensión VC de un clasificador no es importante. Más bien, es usado más para clasificar diferentes tipos de algoritmos por su complejidad; por ejemplo, la clase de clasificadores simples podría incluir figuras basicas como lineas, circulos, o rectangulos, donde la clase de clasificadores complejos puede incluir clasificadores como perceptron de multiples capas, potenciación del gradiente, u otro clasificador no lineal.">

  
  <link rel="alternate" hreflang="es" href="https://ricardohe97.github.io/post/teoria-de-clasificadores/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="hsl(339, 90%, 68%)">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/dracula.min.css" crossorigin="anonymous">
        
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono">
  

  <link rel="stylesheet" href="/styles.css">
  

  
  
  

  
  <link rel="alternate" href="https://ricardohe97.github.io/index.xml" type="application/rss+xml" title="Ricardo Holguin">
  <link rel="feed" href="https://ricardohe97.github.io/index.xml" type="application/rss+xml" title="Ricardo Holguin">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://ricardohe97.github.io/post/teoria-de-clasificadores/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@RichieGCC">
  <meta property="twitter:creator" content="@RichieGCC">
  
  <meta property="og:site_name" content="Ricardo Holguin">
  <meta property="og:url" content="https://ricardohe97.github.io/post/teoria-de-clasificadores/">
  <meta property="og:title" content="Teoría De Clasificadores | Ricardo Holguin">
  <meta property="og:description" content="Dimensión VC La dimensión VC es definido por Vapnik y Chervonenkis, quienes dicen que cada clasificador tiene una dimension VC, el cual es la cardinalidad (tamaño) del conjunto más grande de datos que el clasificador pueda desentrañar.
Es importante entender la importancia práctica de la dimensión VC. En muchos casos, el número exacto de la dimensión VC de un clasificador no es importante. Más bien, es usado más para clasificar diferentes tipos de algoritmos por su complejidad; por ejemplo, la clase de clasificadores simples podría incluir figuras basicas como lineas, circulos, o rectangulos, donde la clase de clasificadores complejos puede incluir clasificadores como perceptron de multiples capas, potenciación del gradiente, u otro clasificador no lineal.">
  
  
    
  <meta property="og:image" content="https://ricardohe97.github.io/img/icon-192.png">
  <meta property="og:locale" content="es">
  
  <meta property="article:published_time" content="2018-11-27T14:28:55-07:00">
  
  <meta property="article:modified_time" content="2018-11-27T14:28:55-07:00">
  

  

  

  <title>Teoría De Clasificadores | Ricardo Holguin</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" class="dark">

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Ricardo Holguin</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Barra de navegación">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Inicio</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contacto</span>
            
          </a>
        </li>

        
        

      

        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Teoría De Clasificadores</h1>

  

  
    

<div class="article-metadata">

  
  
  
  <div>
    <span itemscope itemprop="author" itemtype="http://schema.org/Person">
      <span itemprop="name">Ricardo Holguin Esquer</span>
    </span>
    
  </div>
  

  <span class="article-date">
    
    <meta content="2018-11-27 14:28:55 -0700 MST" itemprop="datePublished">
    <time datetime="2018-11-27 14:28:55 -0700 MST" itemprop="dateModified">
      Tue, 27 Nov 2018
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Ricardo Holguin Esquer">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    5 min de lectura
  </span>
  

  
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Teor%c3%ada%20De%20Clasificadores&amp;url=https%3a%2f%2fricardohe97.github.io%2fpost%2fteoria-de-clasificadores%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fricardohe97.github.io%2fpost%2fteoria-de-clasificadores%2f"
         target="_blank" rel="noopener">
        <i class="fab fa-facebook-f"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fricardohe97.github.io%2fpost%2fteoria-de-clasificadores%2f&amp;title=Teor%c3%ada%20De%20Clasificadores"
         target="_blank" rel="noopener">
        <i class="fab fa-linkedin-in"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fricardohe97.github.io%2fpost%2fteoria-de-clasificadores%2f&amp;title=Teor%c3%ada%20De%20Clasificadores"
         target="_blank" rel="noopener">
        <i class="fab fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Teor%c3%ada%20De%20Clasificadores&amp;body=https%3a%2f%2fricardohe97.github.io%2fpost%2fteoria-de-clasificadores%2f">
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    







  









  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<h2 id="dimensión-vc">Dimensión VC</h2>

<p>La dimensión VC es definido por Vapnik y Chervonenkis, quienes dicen que cada clasificador tiene una dimension VC, el cual es la cardinalidad (tamaño) del conjunto más grande de datos que el clasificador pueda desentrañar.</p>

<p>Es importante entender la importancia práctica de la dimensión VC. En muchos casos, el número exacto de la dimensión VC de un clasificador no es importante. Más bien, es usado más para clasificar diferentes tipos de algoritmos por su complejidad; por ejemplo, la clase de clasificadores simples podría incluir figuras basicas como lineas, circulos, o rectangulos, donde la clase de clasificadores complejos puede incluir clasificadores como perceptron de multiples capas, potenciación del gradiente, u otro clasificador no lineal. La complejidad de un algoritmo de clasificación, el cual es directamente relacionado a su dimensión VC, esta relacionado al intercambio entre el sesgo y varianza</p>

<p>Para ver el comportamiento de la dimensión VC están las siguientes gráficas de una función que depende del tamaño del conjunto de entrenamiento.</p>




<figure>

<img src="dim_vc.png" />



<figcaption data-pre="Figura " data-post=":" class="numbered">
  <h4>$f_{d_v}(x) = N^{d_v}e^{-N}$</h4>
  
</figcaption>

</figure>

<h2 id="aproximación-a-f-x-sen-pi-x-con-diferentes-hipótesis">Aproximación a $f(x) = sen(\pi x)$ con diferentes hipótesis</h2>

<p>A continuación se aproximara la función $f(x) = sen(\pi x)$ con dos hipótesis. Con una hipótesis $H_1$ el cual es una función constante.
Y con una hipótesis $H_2$ el cual es una función lineal.</p>

<p>Las dos hipótesis anteriores se calcularán para 10, 50, 100 y 1000 datos diferentes. Al final se calcularan los sesgos y varianza de los resultados
con la función que se trata de aproximar</p>

<h3 id="h-1">$H_1$</h3>

<p>Para encontrar el valor constante de cada recta, se sacarán dos números aleatorios entre -1 y 1. Y $H_1$ se calculara como $\frac{y_1 + y_2}{2}$,
y el resultado será la recta.</p>

<p>Resultados:



<figure>

<img src="H1-10.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>$H_1$ para 10 datos</h4>
  
</figcaption>

</figure>



<figure>

<img src="H1-50.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>$H_1$ para 50 datos</h4>
  
</figcaption>

</figure>



<figure>

<img src="H1-100.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>$H_1$ para 100 datos</h4>
  
</figcaption>

</figure>



<figure>

<img src="H1-1000.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>$H_1$ para 1000 datos</h4>
  
</figcaption>

</figure></p>

<h4 id="sesgos-y-varianzas-para-h-1">Sesgos y varianzas para $H_1$</h4>

<p>Los sesgos y varianzas de esta hipotesis muestran un resultado que debería de pasar, donde los sesgos poco a poco disminuyen y la varianza
poco a poco van subiendo. Esto es porque se trata de aproximar a la función original y se quiere tener el menor error posible (sesgo), pero al mismo tiempo se trata de generalizar entonces la varianza va aumentando.



<figure>

<img src="H1-Bias_Var.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>Sesgos y varianzas para $H_1$</h4>
  
</figcaption>

</figure></p>

<h3 id="h-2">$H_2$</h3>

<p>$H_2$ es una función lineal, así que como tal se debe de calcular su pendiente y su constante $b$, para al final tener la función $y = mx + b$. Para encontrar esto, se sacan dos números aleatorios entre -1 y 1 para que estos sean las variables $x$ y luego ingresan estos en la función que se trata de aproximar ($f(x) = sen(\pi x)$ y con los valores que salgan serán usados para las variables $y$ y con esto calcular la pendiente. Después de calcular la pendiente, usando la pendiente calculada, una $y$ y una $x$, se calcula $b$. El resulado es una ecuación en su forma $y = mx + b$.</p>

<p>Resultados:



<figure>

<img src="H2-10.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>$H_2$ para 10 datos</h4>
  
</figcaption>

</figure>



<figure>

<img src="H2-50.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>$H_2$ para 50 datos</h4>
  
</figcaption>

</figure>



<figure>

<img src="H2-100.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>$H_2$ para 100 datos</h4>
  
</figcaption>

</figure>



<figure>

<img src="H2-1000.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>$H_2$ para 1000 datos</h4>
  
</figcaption>

</figure></p>

<h4 id="sesgos-y-varianzas-para-h-2">Sesgos y varianzas para $H_2$</h4>

<p>Aquí los resultados son más caóticos, y tienen sentido de porque. Sabemos que la función es $f(x) = Sen(\pi x)$ y los valores que puede dar esta función siempre están entre -1 y 1, y es posible que muchas  de las rectas que se calculen tengan una pendiente los suficientemente bastante alta para que cuando se calcule el error este sea muy alto en ciertos puntos de $x$. Pero también se puede notar que cuando se calculan muchas rectas el sesgo y la varianza llegan a ser poco y estos están más cercanos.



<figure>

<img src="H2-Bias_Var.png" />



<figcaption data-pre="Figura " data-post=":" >
  <h4>Sesgos y varianzas para $H_2$</h4>
  
</figcaption>

</figure></p>

<h2 id="ajuste-de-polinomios">Ajuste de polinomios</h2>

<p>Cuando se quiere aproximar a una función también se debe tomar en cuenta una cosa importante: el ruido. El ruido puede ser determinista o estocástico. El ruido estocástico es el ruido que puede haber en nuestros datos y el ruido determinista es el ruido que puede haber cuando la función que se trata de modelar es muy complejo.</p>

<h4 id="ejercicio-de-ruido-estocástico">Ejercicio de ruido estocástico</h4>

<p>A continuación se tratará de ajustar un polinomio de bessel, especificamente una función modificada de Bessel de segundo tipo de orden 2. Y a cada punto y que se genere se le agregará un ruido calculada con una distribución normal con un $\sigma = 1.2$ y $\mu = 0$. Los polinomios con los que se tratará de ajustar serán de orden 2 y orden 3, esto con la finalidad de ver con que grado de polinomio resultan con menos error. El siguiente codigo muestra como hacer este ejercicio.</p>

<pre><code class="language-python">import numpy as np
import scipy.special

def generar_datos(N, n, sigma, Q):
    &quot;&quot;&quot;
    @N numero de datos para entrenamiento
    @n Numero de datos
    @sigma Desviacion estandar
    @Q orden del polinomio
    &quot;&quot;&quot;
    D = scipy.special.kn(Q, n) + np.random.normal(loc=0.0, scale=1.2, size=n)
    x_t = np.random.choice(range(n), N)
    D_t = D[x_t]
    return D, D_t, x_t

def delta(D, D_t, x_t):
    &quot;&quot;&quot;
    @D datos
    @D_t datos de entrenamiento
    @x_t datos de $x$ para evaluar los polinomios
    &quot;&quot;&quot;
    y_2 = np.polyval(np.polyfit(x_t, D_t, 2), range(len(D)))
    y_10 = np.polyval(np.polyfit(x_t, D_t, 10), range(len(D)))

    E_2 = np.mean((D - y_2)**2)
    E_10 = np.mean((D - y_10)**2)
    return E_10 - E_2, E_10, E_2

</code></pre>

<pre><code class="language-python">&gt;&gt;&gt; D, D_t, x_t = generar_datos(80, 1000, 1, 2)

&gt;&gt;&gt; delta(D, D_t, x_t)
(0.15908868155723654, 1.637024755415497, 1.4779360738582605)

</code></pre>

<p>Con los resultados anteriores se puede apreciar que el error que se tiene con un polinomio de grado 2 es menor que el que se tiene con el polinomio de grado 10, por lo que en este caso es mejor usar el polinomio de grado 2</p>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/teoria-del-aprendizaje/">Teoria del aprendizaje</a>
  
  <a class="badge badge-light" href="/tags/sesgo/">Sesgo</a>
  
  <a class="badge badge-light" href="/tags/varianza/">Varianza</a>
  
  <a class="badge badge-light" href="/tags/bias/">bias</a>
  
  <a class="badge badge-light" href="/tags/var/">var</a>
  
  <a class="badge badge-light" href="/tags/ruido/">Ruido</a>
  
</div>



    



  




<div class="media author-card" itemscope itemtype="http://schema.org/Person">
  
  <img class="portrait mr-3" src="/img/portrait.jpg" itemprop="image" alt="Avatar">
  
  <div class="media-body">
    <h5 class="card-title" itemprop="name"><a href="/">Ricardo Holguin Esquer</a></h5>
    <h6 class="card-subtitle">Estudiante de Ciencias de la computación</h6>
    
    <ul class="network-icon" aria-hidden="true">
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="/rholguinesquer@gmail.com" >
          <i class="fas fa-envelope"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://twitter.com/RichieGCC" target="_blank" rel="noopener">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
      
      
      
      
        
      
      
      
      
      
        
      
      <li>
        <a itemprop="sameAs" href="https://github.com/RicardoHE97" target="_blank" rel="noopener">
          <i class="fab fa-github"></i>
        </a>
      </li>
      
    </ul>
  </div>
</div>




    
    

    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2018 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Citar</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copiar
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Descargar
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    
    <script src="/js/mathjax-config.500a6cbb2c0f345fcecc21b3116d6637aa78f1f11db8081ea581abe05390c2e8f3bbffe61be3cf0217baf785c40efceabe51050a4f007e69af94efd3643260e8.js" integrity="sha512-UApsuywPNF/OzCGzEW1mN6p48fEduAgepYGr4FOQwujzu//mG&#43;PPAhe694XEDvzqvlEFCk8AfmmvlO/TZDJg6A=="></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "",
        'results': "",
        'no_results': ""
      };
      const content_type = {
        'post': "Posts",
        'project': "Proyectos",
        'publication' : "Publicaciones",
        'talk' : "Conferencias"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    <script src="/js/search.js"></script>
    

    
    

  </body>
</html>

